LOGS TOTAL
  75

ERRORS TOTAL
  375

ERRORS COUNT

  151 ./kind-1.kubeconfig/kube-system/kube-controller-manager-kind-1-control-plane/logs.txt
  34 ./kind-2.kubeconfig/nsm-system/wcm-proxy-nsmgr-7599b46ff-7vvln/logs.txt
  23 ./kind-2.kubeconfig/default/member-core-operator-d598d4888-249n4/logs.txt
  21 ./kind-2.kubeconfig/wcm-system/wcm-nse-discovery-6fd76df87f-pr6ph/logs.txt
  18 ./kind-1.kubeconfig/wcm-system/connectivity-domain-operator-7cb485f58d-hzf92/logs.txt
  15 ./kind-3.kubeconfig/default/member-core-operator-d598d4888-x9zhs/logs.txt
  10 ./kind-1.kubeconfig/spire/spire-agent-jlz48/logs.txt
  9 ./kind-3.kubeconfig/spire/wcm-spire-agent-x96z4/logs.txt
  9 ./kind-2.kubeconfig/spire/wcm-spire-agent-cx49v/logs.txt
  8 ./kind-2.kubeconfig/wcm-system/vl3-nse-green-76bc7f4b96-pfsst/logs.txt
  8 ./kind-2.kubeconfig/wcm-system/vl3-nse-green-76bc7f4b96-fx2bm/logs.txt
  7 ./kind-3.kubeconfig/wcm-system/vl3-nse-green-7555496c4c-xvfj4/logs.txt
  7 ./kind-3.kubeconfig/wcm-system/vl3-nse-green-7555496c4c-blkt5/logs.txt
  6 ./kind-1.kubeconfig/spire/spire-server-0/logs.txt
  5 ./kind-2.kubeconfig/wcm-system/wcm-nse-operator-6fb5b6fb4c-8mfgn/logs.txt
  4 ./kind-3.kubeconfig/spire/wcm-spire-server-0/logs.txt
  4 ./kind-2.kubeconfig/spire/wcm-spire-server-0/logs.txt
  4 ./kind-2.kubeconfig/nsm-system/wcm-nsmgr-wk2j2/logs.txt
  4 ./kind-1.kubeconfig/istio-system/istiod-85c587c85c-8mwdb/logs.txt
  3 ./kind-3.kubeconfig/kube-system/kube-controller-manager-kind-3-control-plane/logs.txt
  3 ./kind-1.kubeconfig/wcm-system/green-bfd874d66-9xj9n/logs.txt
  2 ./kind-3.kubeconfig/wcm-system/wcm-nse-operator-6fb5b6fb4c-5rllm/logs.txt
  2 ./kind-3.kubeconfig/nsm-system/wcm-nsm-vpp-forwarder-c4fzl/logs.txt
  2 ./kind-2.kubeconfig/nsm-system/wcm-nsm-vpp-forwarder-d48fj/logs.txt
  2 ./kind-2.kubeconfig/kube-system/kube-controller-manager-kind-2-control-plane/logs.txt
  2 ./kind-1.kubeconfig/istio-system/istio-ingressgateway-5c658595cb-7tdb8/logs.txt
  1 ./kind-3.kubeconfig/nsm-system/wcm-jaeger-86c548cd44-fbfqn/logs.txt
  1 ./kind-3.kubeconfig/nsm-system/wcm-crossconnect-monitor-c4db96966-wqgns/logs.txt
  1 ./kind-3.kubeconfig/kube-system/kube-scheduler-kind-3-control-plane/logs.txt
  1 ./kind-3.kubeconfig/kube-system/kindnet-mzh7w/logs.txt
  1 ./kind-2.kubeconfig/nsm-system/wcm-jaeger-86c548cd44-2kdbm/logs.txt
  1 ./kind-2.kubeconfig/nsm-system/wcm-crossconnect-monitor-c4db96966-wv9vn/logs.txt
  1 ./kind-2.kubeconfig/kube-system/kube-scheduler-kind-2-control-plane/logs.txt
  1 ./kind-2.kubeconfig/kube-system/kindnet-xwjsq/logs.txt
  1 ./kind-1.kubeconfig/wcm-system/wcm-etcd-cluster-wjgxlzslq6/logs.txt
  1 ./kind-1.kubeconfig/metallb-system/controller-65895b47d4-6gmm8/logs.txt
  1 ./kind-1.kubeconfig/kube-system/kube-scheduler-kind-1-control-plane/logs.txt
  1 ./kind-1.kubeconfig/kube-system/kindnet-x4k7j/logs.txt

ERRORS OCCURENCES

  ./kind-3.kubeconfig/default/member-core-operator-d598d4888-x9zhs/logs.txt
  
  	36:{"level":"error","ts":1623682185.73145,"logger":"controller_membercore","msg":"An error occurred","component":"Spire Server","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:261\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	37:{"level":"error","ts":1623682185.7377043,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	38:{"level":"error","ts":1623682185.7379076,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	244:{"level":"error","ts":1623682198.4581711,"logger":"controller_membercore","msg":"An error occurred","component":"NSM common","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:414\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	245:{"level":"error","ts":1623682198.4586744,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	246:{"level":"error","ts":1623682198.4590974,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	311:{"level":"error","ts":1623682199.6853745,"logger":"controller_membercore","msg":"An error occurred","component":"NSM common","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:443\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	312:{"level":"error","ts":1623682199.6857414,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	313:{"level":"error","ts":1623682199.6859522,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	414:{"level":"error","ts":1623682201.4532027,"logger":"controller_membercore","msg":"An error occurred","component":"NSM admission Webhook","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:594\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	415:{"level":"error","ts":1623682201.4570122,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	416:{"level":"error","ts":1623682201.4570951,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	739:{"level":"error","ts":1623682207.5561879,"logger":"controller_membercore","msg":"An error occurred","component":"NSE discovery","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:749\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	740:{"level":"error","ts":1623682207.5563145,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	741:{"level":"error","ts":1623682207.5563831,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  
  
  ./kind-3.kubeconfig/nsm-system/wcm-crossconnect-monitor-c4db96966-wqgns/logs.txt
  
  	35:time="2021-06-14T14:50:02Z" level=error msg="failed to read PROMETHEUS env var"
  
  
  ./kind-3.kubeconfig/nsm-system/wcm-nsm-vpp-forwarder-c4fzl/logs.txt
  
  	104:time="2021-06-14 14:50:08.41701" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	168:time="2021-06-14 14:50:08.69778" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  
  
  ./kind-3.kubeconfig/nsm-system/wcm-jaeger-86c548cd44-fbfqn/logs.txt
  
  	16:{"level":"info","ts":1623682203.603931,"caller":"grpc/clientconn.go:1139","msg":"grpc: addrConn.createTransport failed to connect to {127.0.0.1:14250 0  <nil>}. Err :connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:14250: connect: connection refused\". Reconnecting...","system":"grpc","grpc_log":true}
  
  
  ./kind-3.kubeconfig/spire/wcm-spire-server-0/logs.txt
  
  	62:time="2021-06-14T14:49:54Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=central.com
  	78:time="2021-06-14T14:50:54Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=central.com
  	80:time="2021-06-14T14:50:54Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  	81:time="2021-06-14T14:50:55Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  
  
  ./kind-3.kubeconfig/spire/wcm-spire-agent-x96z4/logs.txt
  
  	183:time="2021-06-14T14:51:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	195:time="2021-06-14T14:52:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	207:time="2021-06-14T14:53:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	219:time="2021-06-14T14:54:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	231:time="2021-06-14T14:55:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	304:time="2021-06-14T14:56:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	332:time="2021-06-14T14:57:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	392:time="2021-06-14T14:58:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	444:time="2021-06-14T14:59:06Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  
  
  ./kind-3.kubeconfig/wcm-system/vl3-nse-green-7555496c4c-blkt5/logs.txt
  
  	52:time="2021-06-14 14:58:56.31229" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	126:time="2021-06-14T14:59:16Z" level=error msg="Error occurred while trying to establish connection to: wcm-nsmgr.nsm-system:5000. Error: context deadline exceeded"
  	127:time="2021-06-14T14:59:16Z" level=error msg="nsmRegistryConnection GRPC Client Socket Error: context deadline exceeded"
  	147:time="2021-06-14T14:59:36Z" level=error msg="Error occurred while trying to establish connection to: /var/lib/networkservicemesh/nsm.server.io.sock. Error: context deadline exceeded"
  	148:time="2021-06-14T14:59:36Z" level=error msg="nse: failure to communicate with the registrySocket /var/lib/networkservicemesh/nsm.server.io.sock with error: context deadline exceeded"
  	149:time="2021-06-14T14:59:36Z" level=error msg="Error: context deadline exceeded"
  	150:time="2021-06-14T14:59:36Z" level=error msg="Unable to create the NSM client context deadline exceeded"
  
  
  ./kind-3.kubeconfig/wcm-system/wcm-nse-operator-6fb5b6fb4c-5rllm/logs.txt
  
  	13:{"level":"info","ts":1623682186.8451598,"logger":"cmd","msg":"Could not create ServiceMonitor object","error":"no ServiceMonitor registered with the API"}
  	14:{"level":"info","ts":1623682186.8453083,"logger":"cmd","msg":"Install prometheus-operator in your cluster to create ServiceMonitor objects","error":"no ServiceMonitor registered with the API"}
  
  
  ./kind-3.kubeconfig/wcm-system/vl3-nse-green-7555496c4c-xvfj4/logs.txt
  
  	52:time="2021-06-14 14:58:55.46598" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	126:time="2021-06-14T14:59:16Z" level=error msg="Error occurred while trying to establish connection to: wcm-nsmgr.nsm-system:5000. Error: context deadline exceeded"
  	127:time="2021-06-14T14:59:16Z" level=error msg="nsmRegistryConnection GRPC Client Socket Error: context deadline exceeded"
  	147:time="2021-06-14T14:59:36Z" level=error msg="Error occurred while trying to establish connection to: /var/lib/networkservicemesh/nsm.server.io.sock. Error: context deadline exceeded"
  	148:time="2021-06-14T14:59:36Z" level=error msg="nse: failure to communicate with the registrySocket /var/lib/networkservicemesh/nsm.server.io.sock with error: context deadline exceeded"
  	149:time="2021-06-14T14:59:36Z" level=error msg="Error: context deadline exceeded"
  	150:time="2021-06-14T14:59:36Z" level=error msg="Unable to create the NSM client context deadline exceeded"
  
  
  ./kind-3.kubeconfig/kube-system/kube-scheduler-kind-3-control-plane/logs.txt
  
  	6:W0614 14:43:09.232858       1 authentication.go:296] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
  
  
  ./kind-3.kubeconfig/kube-system/kindnet-mzh7w/logs.txt
  
  	4:I0614 14:44:01.030777       1 main.go:104] Failed to get nodes, retrying after error: Get https://10.96.0.1:443/api/v1/nodes: dial tcp 10.96.0.1:443: i/o timeout
  
  
  ./kind-3.kubeconfig/kube-system/kube-controller-manager-kind-3-control-plane/logs.txt
  
  	10:E0614 14:43:09.233844       1 leaderelection.go:331] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"
  	180:E0614 14:43:27.107014       1 daemon_controller.go:290] kube-system/kube-proxy failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-proxy", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/kube-proxy", UID:"fd30c327-60cc-4f42-8fcf-81be32edab16", ResourceVersion:"216", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63759278592, loc:(*time.Location)(0x399e9e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc00059ce40), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-proxy", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc0013ae040), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00059ce60), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc00059ce80), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kube-proxy", Image:"k8s.gcr.io/kube-proxy:v1.17.5", Command:[]string{"/usr/local/bin/kube-proxy", "--config=/var/lib/kube-proxy/config.conf", "--hostname-override=$(NODE_NAME)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc00059cec0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-proxy", ReadOnly:false, MountPath:"/var/lib/kube-proxy", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0000c9e50), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000661048), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"kube-proxy", DeprecatedServiceAccount:"kube-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0010baae0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00026eac0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc0006610b8)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kube-proxy": the object has been modified; please apply your changes to the latest version and try again
  	199:E0614 14:49:40.629740       1 daemon_controller.go:290] metallb-system/speaker failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"speaker", GenerateName:"", Namespace:"metallb-system", SelfLink:"/apis/apps/v1/namespaces/metallb-system/daemonsets/speaker", UID:"7173b33e-41fa-42dc-8b12-4984187a9806", ResourceVersion:"1472", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63759278980, loc:(*time.Location)(0x399e9e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "app.kubernetes.io/managed-by":"Helm", "component":"speaker"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1", "meta.helm.sh/release-name":"metallb-system-release", "meta.helm.sh/release-namespace":"default"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc000522bc0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"metallb", "component":"speaker"}, Annotations:map[string]string{"prometheus.io/port":"7472", "prometheus.io/scrape":"true"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume(nil), InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"speaker", Image:"metallb/speaker:v0.8.2", Command:[]string(nil), Args:[]string{"--port=7472", "--config=config"}, WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"monitoring", HostPort:7472, ContainerPort:7472, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"METALLB_NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000522c00)}, v1.EnvVar{Name:"METALLB_HOST", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc000522cc0)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:104857600, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100Mi", Format:"BinarySI"}}, Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount(nil), VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc001284d70), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000a04d90), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"speaker", DeprecatedServiceAccount:"speaker", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000619680), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node-role.kubernetes.io/master", Operator:"", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0016c6bc8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc000a04dec)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "speaker": the object has been modified; please apply your changes to the latest version and try again
  
  
  ./kind-1.kubeconfig/spire/spire-agent-jlz48/logs.txt
  
  	26:time="2021-06-14T14:50:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	30:time="2021-06-14T14:51:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	34:time="2021-06-14T14:52:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	38:time="2021-06-14T14:53:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	42:time="2021-06-14T14:54:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	58:time="2021-06-14T14:55:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	101:time="2021-06-14T14:56:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	105:time="2021-06-14T14:57:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	109:time="2021-06-14T14:58:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	113:time="2021-06-14T14:59:27Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  
  
  ./kind-1.kubeconfig/spire/spire-server-0/logs.txt
  
  	43:time="2021-06-14T14:49:13Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=member2.com
  	45:time="2021-06-14T14:49:13Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=member1.com
  	57:time="2021-06-14T14:50:13Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=member1.com
  	58:time="2021-06-14T14:50:13Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=member2.com
  	61:time="2021-06-14T14:50:53Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  	62:time="2021-06-14T14:50:54Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  
  
  ./kind-1.kubeconfig/metallb-system/controller-65895b47d4-6gmm8/logs.txt
  
  	15:{"caller":"service.go:85","error":"controller not synced","msg":"controller not synced yet, cannot allocate IP; will retry after sync","op":"allocateIP","service":"spire/spire-server","ts":"2021-06-14T14:49:24.132332399Z"}
  
  
  ./kind-1.kubeconfig/wcm-system/connectivity-domain-operator-7cb485f58d-hzf92/logs.txt
  
  	12:{"level":"info","ts":1623682166.3217978,"logger":"cmd","msg":"Could not create metrics Service","error":"failed to initialize service object for metrics: replicasets.apps \"connectivity-domain-operator-7cb485f58d\" is forbidden: User \"system:serviceaccount:wcm-system:connectivity-domain-operator-service-account\" cannot get resource \"replicasets\" in API group \"apps\" in the namespace \"wcm-system\""}
  	13:{"level":"info","ts":1623682166.773511,"logger":"cmd","msg":"Could not create ServiceMonitor object","error":"no ServiceMonitor registered with the API"}
  	14:{"level":"info","ts":1623682166.7736342,"logger":"cmd","msg":"Install prometheus-operator in your cluster to create ServiceMonitor objects","error":"no ServiceMonitor registered with the API"}
  	47:{"level":"error","ts":1623682529.7878504,"logger":"controller_connectivitydomain","msg":"An error occurred","component":"WCMD","method":"UpdateObject","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*ReconcileConnectivityDomain).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:287\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	48:{"level":"error","ts":1623682529.7882128,"logger":"controller_connectivitydomain","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain","request namespace":"wcm-system","request name":"green","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile.func1\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:106\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	49:{"level":"error","ts":1623682529.788625,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomain-controller","name":"green","namespace":"wcm-system","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	65:{"level":"error","ts":1623682530.8418205,"logger":"controller_connectivitydomain","msg":"An error occurred","component":"WCMD","method":"UpdateObject","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*ReconcileConnectivityDomain).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:307\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	66:{"level":"error","ts":1623682530.8420455,"logger":"controller_connectivitydomain","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain","request namespace":"wcm-system","request name":"green","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile.func1\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:106\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	67:{"level":"error","ts":1623682530.84256,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomain-controller","name":"green","namespace":"wcm-system","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	141:{"level":"error","ts":1623682532.760205,"logger":"controller_connectivitydomain","msg":"An error occurred","component":"istio","method":"UpdateObject","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*ReconcileConnectivityDomain).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:387\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	142:{"level":"error","ts":1623682532.7614057,"logger":"controller_connectivitydomain","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain","request namespace":"wcm-system","request name":"green","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile.func1\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:106\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	143:{"level":"error","ts":1623682532.7615578,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomain-controller","name":"green","namespace":"wcm-system","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	193:{"level":"error","ts":1623682533.90405,"logger":"controller_connectivitydomain","msg":"An error occurred","component":"WCMD","method":"UpdateObject","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*ReconcileConnectivityDomain).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:411\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	194:{"level":"error","ts":1623682533.9044073,"logger":"controller_connectivitydomain","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain","request namespace":"wcm-system","request name":"green","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile.func1\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:106\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	195:{"level":"error","ts":1623682533.9044795,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomain-controller","name":"green","namespace":"wcm-system","error":"Operation cannot be fulfilled on connectivitydomains.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	253:{"level":"error","ts":1623682535.0635889,"logger":"controller_connectivitydomain","msg":"An error occurred","component":"istio","method":"UpdateObject","error":"virtualservices.networking.istio.io \"grpc-green\" already exists","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*ReconcileConnectivityDomain).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:427\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	254:{"level":"error","ts":1623682535.0637372,"logger":"controller_connectivitydomain","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain","request namespace":"wcm-system","request name":"green","error":"virtualservices.networking.istio.io \"grpc-green\" already exists","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile.func1\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:106\ncisco-app-networking.github.io/wcm-api/connectivity-domain-operator/pkg/controller/connectivitydomain.(*LoggingConnectivityDomainReconciler).Reconcile\n\tconnectivity-domain-operator/pkg/controller/connectivitydomain/connectivitydomain_controller.go:117\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	255:{"level":"error","ts":1623682535.0639074,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomain-controller","name":"green","namespace":"wcm-system","error":"virtualservices.networking.istio.io \"grpc-green\" already exists","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  
  
  ./kind-1.kubeconfig/wcm-system/green-bfd874d66-9xj9n/logs.txt
  
  	10:2021/06/14 14:55:30 ERROR: Reference contains invalid type of SpanReference: {}
  	12:2021/06/14 14:55:30 ERROR: Reference contains invalid type of SpanReference: {}
  	27:2021/06/14 14:55:30 ERROR: Reference contains invalid type of SpanReference: {}
  
  
  ./kind-1.kubeconfig/wcm-system/wcm-etcd-cluster-wjgxlzslq6/logs.txt
  
  	105:WARNING: 2021/06/14 14:49:46 grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
  
  
  ./kind-1.kubeconfig/kube-system/kube-controller-manager-kind-1-control-plane/logs.txt
  
  	10:E0614 14:42:08.927219       1 leaderelection.go:331] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"
  	178:E0614 14:42:28.939420       1 daemon_controller.go:290] kube-system/kube-proxy failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kube-proxy", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/kube-proxy", UID:"34b6e903-cec6-428f-bcf1-7b8d4c704fea", ResourceVersion:"188", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63759278531, loc:(*time.Location)(0x399e9e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0018f5600), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"k8s-app":"kube-proxy"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-proxy", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc00160d180), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0018f5620), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0018f5640), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kube-proxy", Image:"k8s.gcr.io/kube-proxy:v1.17.5", Command:[]string{"/usr/local/bin/kube-proxy", "--config=/var/lib/kube-proxy/config.conf", "--hostname-override=$(NODE_NAME)"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0018f5680)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-proxy", ReadOnly:false, MountPath:"/var/lib/kube-proxy", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0010e9590), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00188ad98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string{"beta.kubernetes.io/os":"linux"}, ServiceAccountName:"kube-proxy", DeprecatedServiceAccount:"kube-proxy", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0018fad80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"CriticalAddonsOnly", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}, v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"system-node-critical", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0000cf7f0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00188add8)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kube-proxy": the object has been modified; please apply your changes to the latest version and try again
  	180:E0614 14:42:28.956157       1 daemon_controller.go:290] kube-system/kindnet failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kindnet", GenerateName:"", Namespace:"kube-system", SelfLink:"/apis/apps/v1/namespaces/kube-system/daemonsets/kindnet", UID:"7e2fc1dc-de96-412b-958a-450ce1e77cd3", ResourceVersion:"206", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63759278532, loc:(*time.Location)(0x399e9e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc0018f56e0), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"kindnet", "k8s-app":"kindnet", "tier":"node"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"cni-cfg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0018f5700), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"xtables-lock", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0018f5720), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"lib-modules", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc0018f5740), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"kindnet-cni", Image:"kindest/kindnetd:0.5.4", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"HOST_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0018f5760)}, v1.EnvVar{Name:"POD_IP", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc0018f57a0)}, v1.EnvVar{Name:"POD_SUBNET", Value:"10.244.0.0/16", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"50Mi", Format:"BinarySI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"cni-cfg", ReadOnly:false, MountPath:"/etc/cni/net.d", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"xtables-lock", ReadOnly:false, MountPath:"/run/xtables.lock", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"lib-modules", ReadOnly:true, MountPath:"/lib/modules", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(0xc0010e96d0), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00188afb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"kindnet", DeprecatedServiceAccount:"kindnet", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:true, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0018fade0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"", Operator:"Exists", Value:"", Effect:"NoSchedule", TolerationSeconds:(*int64)(nil)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc0000cf7f8)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00188b000)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "kindnet": the object has been modified; please apply your changes to the latest version and try again
  	226:E0614 14:50:01.879292       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	227:I0614 14:50:01.879767       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2077", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	244:E0614 14:50:07.605586       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	245:I0614 14:50:07.605654       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2162", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	246:E0614 14:50:17.486940       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	247:I0614 14:50:17.487053       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	249:E0614 14:50:22.609682       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	251:I0614 14:50:22.610092       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	252:E0614 14:50:32.491754       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	253:I0614 14:50:32.491826       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	255:E0614 14:50:37.614895       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	257:I0614 14:50:37.615375       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	258:E0614 14:50:48.104831       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	260:I0614 14:50:48.105092       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	261:E0614 14:50:52.620028       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	262:I0614 14:50:52.620111       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	264:E0614 14:51:03.109497       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	266:I0614 14:51:03.109651       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	267:E0614 14:51:07.626897       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	268:I0614 14:51:07.627010       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	270:E0614 14:51:18.717490       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	272:I0614 14:51:18.717870       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	273:E0614 14:51:22.631510       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	275:I0614 14:51:22.631610       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	276:E0614 14:51:33.722291       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	278:I0614 14:51:33.722538       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	279:E0614 14:51:37.636620       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	281:I0614 14:51:37.637577       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	282:E0614 14:51:49.328763       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	284:I0614 14:51:49.328935       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	285:E0614 14:51:52.644775       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	287:I0614 14:51:52.645088       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	288:E0614 14:52:04.337343       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	290:I0614 14:52:04.337426       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	291:E0614 14:52:07.649870       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	292:I0614 14:52:07.649990       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	294:E0614 14:52:19.944837       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	296:I0614 14:52:19.944930       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	297:E0614 14:52:22.654962       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	298:I0614 14:52:22.655019       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	300:E0614 14:52:34.949101       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	302:I0614 14:52:34.949195       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	303:E0614 14:52:37.659633       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	304:I0614 14:52:37.659706       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	306:E0614 14:52:50.555871       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	308:I0614 14:52:50.556243       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	309:E0614 14:52:52.664298       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	311:I0614 14:52:52.664606       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	312:E0614 14:53:05.560264       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	314:I0614 14:53:05.560869       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	315:E0614 14:53:07.668945       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	317:I0614 14:53:07.669172       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	318:E0614 14:53:21.167669       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	320:I0614 14:53:21.167951       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	321:E0614 14:53:22.681060       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	323:I0614 14:53:22.682104       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	324:E0614 14:53:36.172354       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	326:I0614 14:53:36.172429       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	327:E0614 14:53:37.685243       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	328:I0614 14:53:37.685338       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	330:E0614 14:53:51.779063       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	332:I0614 14:53:51.779167       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	333:E0614 14:53:52.690376       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	335:I0614 14:53:52.690469       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	336:E0614 14:54:06.783340       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	338:I0614 14:54:06.783413       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	339:E0614 14:54:07.694834       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	341:I0614 14:54:07.695204       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	342:E0614 14:54:22.390426       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	343:I0614 14:54:22.390516       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	345:E0614 14:54:22.698992       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	347:I0614 14:54:22.699147       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	348:E0614 14:54:37.394927       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	350:I0614 14:54:37.395080       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	351:E0614 14:54:37.703881       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	353:I0614 14:54:37.703948       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	354:E0614 14:54:53.002372       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	356:I0614 14:54:53.002799       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	357:E0614 14:54:53.006021       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	359:I0614 14:54:53.006420       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	360:E0614 14:55:08.006625       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	362:I0614 14:55:08.006939       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	363:E0614 14:55:08.011238       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	365:I0614 14:55:08.011459       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	366:E0614 14:55:23.613782       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	368:I0614 14:55:23.614009       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	369:E0614 14:55:23.617878       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	370:I0614 14:55:23.617955       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	379:E0614 14:55:38.618075       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	381:I0614 14:55:38.618145       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	382:E0614 14:55:38.622733       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	384:I0614 14:55:38.622843       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	387:E0614 14:55:54.225315       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	389:I0614 14:55:54.225790       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	390:E0614 14:55:54.229112       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	392:I0614 14:55:54.229376       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	393:E0614 14:56:09.230007       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	395:I0614 14:56:09.230318       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	396:E0614 14:56:09.234526       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	398:I0614 14:56:09.234785       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	399:E0614 14:56:24.837470       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	401:I0614 14:56:24.838417       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	402:E0614 14:56:24.852221       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	404:I0614 14:56:24.852647       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	405:E0614 14:56:39.842136       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	407:I0614 14:56:39.842336       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	408:E0614 14:56:39.856792       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	410:I0614 14:56:39.857006       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	411:E0614 14:56:55.449480       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	413:I0614 14:56:55.449759       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	414:E0614 14:56:55.454094       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	416:I0614 14:56:55.454170       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	417:E0614 14:57:10.454563       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	419:I0614 14:57:10.454748       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	420:E0614 14:57:10.458420       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	422:I0614 14:57:10.458613       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	423:E0614 14:57:26.061853       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	425:I0614 14:57:26.062656       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	426:E0614 14:57:26.065601       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	428:I0614 14:57:26.065752       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	429:E0614 14:57:41.067954       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	431:I0614 14:57:41.068478       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	432:E0614 14:57:41.071662       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	434:I0614 14:57:41.071933       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	435:E0614 14:57:56.676395       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	437:I0614 14:57:56.676519       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	438:E0614 14:57:56.680181       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	440:I0614 14:57:56.680434       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	441:E0614 14:58:11.680621       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	443:I0614 14:58:11.681365       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	444:E0614 14:58:11.684658       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	446:I0614 14:58:11.684882       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	447:E0614 14:58:27.287563       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	449:I0614 14:58:27.287738       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	450:E0614 14:58:27.293343       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	452:I0614 14:58:27.293609       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	453:E0614 14:58:42.291994       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	455:I0614 14:58:42.292121       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	456:E0614 14:58:42.297033       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	458:I0614 14:58:42.297118       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	459:E0614 14:58:57.906361       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	461:I0614 14:58:57.907363       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	462:E0614 14:58:57.911934       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	464:I0614 14:58:57.912189       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	465:E0614 14:59:12.916110       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istiod: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	467:I0614 14:59:12.917052       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istiod", UID:"567ab1a9-9e92-4aa0-9786-2d5f39b565db", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2237", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	468:E0614 14:59:12.926746       1 horizontal.go:214] failed to compute desired number of replicas based on listed metrics for Deployment/istio-system/istio-ingressgateway: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  	470:I0614 14:59:12.927184       1 event.go:281] Event(v1.ObjectReference{Kind:"HorizontalPodAutoscaler", Namespace:"istio-system", Name:"istio-ingressgateway", UID:"18d921ec-b540-48a7-be1b-3df2fc53d758", APIVersion:"autoscaling/v2beta2", ResourceVersion:"2265", FieldPath:""}): type: 'Warning' reason: 'FailedComputeMetricsReplicas' invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server could not find the requested resource (get pods.metrics.k8s.io)
  
  
  ./kind-1.kubeconfig/kube-system/kube-scheduler-kind-1-control-plane/logs.txt
  
  	6:W0614 14:42:08.933634       1 authentication.go:296] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
  
  
  ./kind-1.kubeconfig/kube-system/kindnet-x4k7j/logs.txt
  
  	4:I0614 14:43:05.628211       1 main.go:104] Failed to get nodes, retrying after error: Get https://10.96.0.1:443/api/v1/nodes: dial tcp 10.96.0.1:443: i/o timeout
  
  
  ./kind-1.kubeconfig/istio-system/istio-ingressgateway-5c658595cb-7tdb8/logs.txt
  
  	16:2021-06-14T14:49:53.690610Z	info	FLAG: --proxyComponentLogLevel="misc:error"
  	93:2021-06-14T14:49:53.906622Z	info	Envoy command: [-c etc/istio/proxy/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster istio-ingressgateway --service-node router~10.244.0.15~istio-ingressgateway-5c658595cb-7tdb8.istio-system~istio-system.svc.cluster.local --local-address-ip-version v4 --bootstrap-version 3 --log-format-prefix-with-location 0 --log-format %Y-%m-%dT%T.%fZ	%l	envoy %n	%v -l warning --component-log-level misc:error]
  
  
  ./kind-1.kubeconfig/istio-system/istiod-85c587c85c-8mwdb/logs.txt
  
  	128:2021-06-14T14:49:48.911428Z	info	pkica	Failed to get secret (error: secrets "istio-ca-secret" not found), will create one
  	247:2021-06-14T14:49:51.499414Z	info	http: TLS handshake error from 10.244.0.1:52244: remote error: tls: bad certificate
  	255:2021-06-14T14:49:51.532922Z	error	validationController	Failed to update validatingwebhookconfiguration istiod-istio-system (failurePolicy=Fail, resourceVersion=2137): Operation cannot be fulfilled on validatingwebhookconfigurations.admissionregistration.k8s.io "istiod-istio-system": the object has been modified; please apply your changes to the latest version and try again
  	256:2021-06-14T14:49:51.533046Z	error	klog	Operation cannot be fulfilled on validatingwebhookconfigurations.admissionregistration.k8s.io "istiod-istio-system": the object has been modified; please apply your changes to the latest version and try again[]
  
  
  ./kind-2.kubeconfig/default/member-core-operator-d598d4888-249n4/logs.txt
  
  	25:{"level":"error","ts":1623682182.634823,"logger":"controller_membercore","msg":"An error occurred","component":"Spire Bundle","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:239\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	26:{"level":"error","ts":1623682182.6467688,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	27:{"level":"error","ts":1623682182.6471426,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	71:{"level":"error","ts":1623682184.436046,"logger":"controller_membercore","msg":"An error occurred","component":"Spire Server","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:300\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	72:{"level":"error","ts":1623682184.436783,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	73:{"level":"error","ts":1623682184.4371223,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	276:{"level":"error","ts":1623682198.409521,"logger":"controller_membercore","msg":"An error occurred","component":"NSM common","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:414\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	277:{"level":"error","ts":1623682198.4098198,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	278:{"level":"error","ts":1623682198.4100704,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	343:{"level":"error","ts":1623682199.6324933,"logger":"controller_membercore","msg":"An error occurred","component":"NSM common","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:443\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	344:{"level":"error","ts":1623682199.632769,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	345:{"level":"error","ts":1623682199.6329086,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	446:{"level":"error","ts":1623682201.422483,"logger":"controller_membercore","msg":"An error occurred","component":"Jaeger","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:518\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	447:{"level":"error","ts":1623682201.4227893,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	448:{"level":"error","ts":1623682201.4228866,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	569:{"level":"error","ts":1623682203.9009204,"logger":"controller_membercore","msg":"An error occurred","component":"NSM admission Webhook","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:631\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	570:{"level":"error","ts":1623682203.9010358,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	571:{"level":"error","ts":1623682203.9011137,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	850:{"level":"error","ts":1623682209.3547618,"logger":"controller_membercore","msg":"An error occurred","component":"Prefix Service","method":"UpdateObject","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*ReconcileMemberCore).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:728\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	851:{"level":"error","ts":1623682209.355358,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	852:{"level":"error","ts":1623682209.3554573,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	1048:{"level":"error","ts":1623682212.5418744,"logger":"controller_member_core","msg":"An Error occurred","method":"Reconcile","operator":"member core","request namespace":"","request name":"wcm","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile.func1\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:107\ncisco-app-networking.github.io/wcm-api/member-core-operator/pkg/controller/membercore.(*LoggingMemberCoreReconciler).Reconcile\n\tmember-core-operator/pkg/controller/membercore/membercore_controller.go:118\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	1049:{"level":"error","ts":1623682212.542192,"logger":"controller","msg":"Reconciler error","controller":"membercore-controller","name":"wcm","namespace":"","error":"Operation cannot be fulfilled on membercores.wcm.cisco.com \"wcm\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  
  
  ./kind-2.kubeconfig/nsm-system/wcm-jaeger-86c548cd44-2kdbm/logs.txt
  
  	16:{"level":"info","ts":1623682203.2826931,"caller":"grpc/clientconn.go:1139","msg":"grpc: addrConn.createTransport failed to connect to {127.0.0.1:14250 0  <nil>}. Err :connection error: desc = \"transport: Error while dialing dial tcp 127.0.0.1:14250: connect: connection refused\". Reconnecting...","system":"grpc","grpc_log":true}
  
  
  ./kind-2.kubeconfig/nsm-system/wcm-nsmgr-wk2j2/logs.txt
  
  	1594:time="2021-06-14T14:56:52Z" level=error msg="Cannot forward NSE Registration: rpc error: code = Unknown desc = NSMRS Address variable was not set" operation=nsmgr.RegisterNSE span="0c668b5927023a2d:2834d552471f6733:780ea723935ec0a5:1"
  	1642:time="2021-06-14T14:56:52Z" level=error msg="Cannot forward NSE Registration: rpc error: code = Unknown desc = NSMRS Address variable was not set" operation=nsmgr.RegisterNSE span="2700ac51c0ec4531:402336a29be692d0:5d9a237129ef20e2:1"
  	1876:time="2021-06-14T14:58:52Z" level=warning msg="Error forwarding BulkRegisterNSE request to wcm-proxy-nsmgr:5005 : EOF" operation=ProxyNsmgr.BulkRegisterNSE span="2322dcd96c8c6747:6e5639971ab603a1:1c08cb0f52004a5b:1"
  	1917:time="2021-06-14T14:58:52Z" level=warning msg="Error forwarding BulkRegisterNSE request to wcm-proxy-nsmgr:5005 : EOF" operation=ProxyNsmgr.BulkRegisterNSE span="6aab2d859288bc3e:345962a51277a121:51dac9bf03eeeeae:1"
  
  
  ./kind-2.kubeconfig/nsm-system/wcm-crossconnect-monitor-c4db96966-wv9vn/logs.txt
  
  	35:time="2021-06-14T14:50:02Z" level=error msg="failed to read PROMETHEUS env var"
  
  
  ./kind-2.kubeconfig/nsm-system/wcm-proxy-nsmgr-7599b46ff-7vvln/logs.txt
  
  	245:time="2021-06-14T14:57:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	247:time="2021-06-14T14:57:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	249:time="2021-06-14T14:57:52Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	250:time="2021-06-14T14:57:52Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="3d3089b82d96abfc:3d3089b82d96abfc:0000000000000000:1"
  	252:time="2021-06-14T14:57:52Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	275:time="2021-06-14T14:57:52Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	276:time="2021-06-14T14:57:52Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="3db9964bb3c762d1:3db9964bb3c762d1:0000000000000000:1"
  	278:time="2021-06-14T14:57:52Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	295:time="2021-06-14T14:58:02Z" level=error msg="None of the tls certificates worked: <nil>"
  	297:time="2021-06-14T14:58:03Z" level=error msg="None of the tls certificates worked: <nil>"
  	299:time="2021-06-14T14:58:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	300:time="2021-06-14T14:58:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="0c93ad5b56f69ad0:0c93ad5b56f69ad0:0000000000000000:1"
  	302:time="2021-06-14T14:58:22Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	325:time="2021-06-14T14:58:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	326:time="2021-06-14T14:58:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="6950da70ab3bd275:6950da70ab3bd275:0000000000000000:1"
  	328:time="2021-06-14T14:58:22Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	345:time="2021-06-14T14:58:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	347:time="2021-06-14T14:58:33Z" level=error msg="None of the tls certificates worked: <nil>"
  	349:time="2021-06-14T14:58:52Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	350:time="2021-06-14T14:58:52Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="380c485bf77aa830:380c485bf77aa830:0000000000000000:1"
  	352:time="2021-06-14T14:58:52Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	375:time="2021-06-14T14:58:53Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	376:time="2021-06-14T14:58:53Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="612b8216f6d1839d:612b8216f6d1839d:0000000000000000:1"
  	378:time="2021-06-14T14:58:53Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	395:time="2021-06-14T14:59:02Z" level=error msg="None of the tls certificates worked: <nil>"
  	397:time="2021-06-14T14:59:03Z" level=error msg="None of the tls certificates worked: <nil>"
  	409:time="2021-06-14T14:59:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	410:time="2021-06-14T14:59:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="35ab9d4cb020f0c6:35ab9d4cb020f0c6:0000000000000000:1"
  	412:time="2021-06-14T14:59:22Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	435:time="2021-06-14T14:59:23Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	436:time="2021-06-14T14:59:23Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="4dfd836c65e9697a:4dfd836c65e9697a:0000000000000000:1"
  	438:time="2021-06-14T14:59:23Z" level=error msg="rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	455:time="2021-06-14T14:59:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	457:time="2021-06-14T14:59:33Z" level=error msg="None of the tls certificates worked: <nil>"
  
  
  ./kind-2.kubeconfig/nsm-system/wcm-nsm-vpp-forwarder-d48fj/logs.txt
  
  	104:time="2021-06-14 14:50:09.32889" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	133:time="2021-06-14 14:50:09.58448" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  
  
  ./kind-2.kubeconfig/spire/wcm-spire-server-0/logs.txt
  
  	62:time="2021-06-14T14:49:52Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=central.com
  	78:time="2021-06-14T14:50:52Z" level=error msg="Error updating bundle" error="local bundle not found" subsystem_name=bundle_client trust_domain=central.com
  	80:time="2021-06-14T14:50:54Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  	81:time="2021-06-14T14:50:55Z" level=error msg="Bundle not found" method=fetch_federated_bundle subsystem_name=registration_api
  
  
  ./kind-2.kubeconfig/spire/wcm-spire-agent-cx49v/logs.txt
  
  	183:time="2021-06-14T14:50:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	195:time="2021-06-14T14:51:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	207:time="2021-06-14T14:52:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	219:time="2021-06-14T14:53:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	231:time="2021-06-14T14:54:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	253:time="2021-06-14T14:55:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	334:time="2021-06-14T14:56:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	451:time="2021-06-14T14:57:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  	511:time="2021-06-14T14:58:41Z" level=error msg="No identity issued" error="<nil>" registered=false subsystem_name=workload_api
  
  
  ./kind-2.kubeconfig/wcm-system/vl3-nse-green-76bc7f4b96-pfsst/logs.txt
  
  	52:time="2021-06-14 14:55:52.00637" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	100:time="2021-06-14T14:56:22Z" level=error msg="None of the tls certificates worked: <nil>"
  	102:time="2021-06-14T14:56:22Z" level=error msg="Error occurred while trying to establish connection to: wcmd-green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	245:time="2021-06-14 14:57:22.31954" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	388:time="2021-06-14T14:57:52Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	413:time="2021-06-14T14:58:22Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	439:time="2021-06-14T14:58:53Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	465:time="2021-06-14T14:59:23Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  
  
  ./kind-2.kubeconfig/wcm-system/vl3-nse-green-76bc7f4b96-fx2bm/logs.txt
  
  	50:time="2021-06-14 14:55:51.82269" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	100:time="2021-06-14T14:56:22Z" level=error msg="None of the tls certificates worked: <nil>"
  	102:time="2021-06-14T14:56:22Z" level=error msg="Error occurred while trying to establish connection to: wcmd-green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	247:time="2021-06-14 14:57:22.40230" level=warning msg="grpc: Server.Serve failed to create ServerTransport: connection error: desc = \"transport: http2Server.HandleStreams failed to receive the preface from client: EOF\"" loc="grpclog/grpclog.go(42)" logger=grpc.grpc-server
  	343:time="2021-06-14T14:57:52Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	368:time="2021-06-14T14:58:22Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	394:time="2021-06-14T14:58:52Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  	418:time="2021-06-14T14:59:22Z" level=error msg="failed to find network service green@green.nispatil-wcm-cisco.com: rpc error: code = Unavailable desc = Connection to Network Registry Server is not available"
  
  
  ./kind-2.kubeconfig/wcm-system/wcm-nse-discovery-6fd76df87f-pr6ph/logs.txt
  
  	103:time="2021-06-14T14:57:02Z" level=error msg="None of the tls certificates worked: <nil>"
  	105:time="2021-06-14T14:57:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	106:time="2021-06-14T14:57:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="34a506338c7d2c1d:3ac8d0aeec8e7420:34a506338c7d2c1d:1"
  	109:{"level":"info","ts":1623682642.346188,"caller":"nseinformer/nseInformerController.go:369","msg":"Error processing pod &{{ } {greenqvhtb green nsm-system /apis/networkservicemesh.io/v1alpha1/namespaces/nsm-system/networkserviceendpoints/greenqvhtb d0a5ebca-6c3f-4d65-b4cc-027bf680eba5 3283 1 2021-06-14 14:56:52 +0000 UTC <nil> <nil> map[app:vl3-nse-green networkservicename:green nsepod.name:green-kind-2_vl3-nse-green-76bc7f4b96-fx2bm wcm/nsr.addr:green.nispatil-wcm-cisco.com wcm/nsr.port:443] map[] [] []  []} {green IP kind-2-control-plane} {RUNNING}}: Connection to Network Registry Server is not available","app":"nse-discovery"}
  	157:time="2021-06-14T14:57:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	159:time="2021-06-14T14:57:52Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	160:time="2021-06-14T14:57:52Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="6f51526ab0968849:20ddd059d9665736:6f51526ab0968849:1"
  	163:{"level":"info","ts":1623682672.4022706,"caller":"nseinformer/nseInformerController.go:369","msg":"Error processing pod &{{ } {green7k6bh green nsm-system /apis/networkservicemesh.io/v1alpha1/namespaces/nsm-system/networkserviceendpoints/green7k6bh c8c7c650-9263-4013-bfab-a8b4d8edd0e1 3284 1 2021-06-14 14:56:52 +0000 UTC <nil> <nil> map[app:vl3-nse-green networkservicename:green nsepod.name:green-kind-2_vl3-nse-green-76bc7f4b96-pfsst wcm/nsr.addr:green.nispatil-wcm-cisco.com wcm/nsr.port:443] map[] [] []  []} {green IP kind-2-control-plane} {RUNNING}}: Connection to Network Registry Server is not available","app":"nse-discovery"}
  	211:time="2021-06-14T14:58:02Z" level=error msg="None of the tls certificates worked: <nil>"
  	215:time="2021-06-14T14:58:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	216:time="2021-06-14T14:58:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="41d18d07c0002777:437143452aaa0ad8:41d18d07c0002777:1"
  	219:{"level":"info","ts":1623682702.4391234,"caller":"nseinformer/nseInformerController.go:369","msg":"Error processing pod &{{ } {greenqvhtb green nsm-system /apis/networkservicemesh.io/v1alpha1/namespaces/nsm-system/networkserviceendpoints/greenqvhtb d0a5ebca-6c3f-4d65-b4cc-027bf680eba5 3283 1 2021-06-14 14:56:52 +0000 UTC <nil> <nil> map[app:vl3-nse-green networkservicename:green nsepod.name:green-kind-2_vl3-nse-green-76bc7f4b96-fx2bm wcm/nsr.addr:green.nispatil-wcm-cisco.com wcm/nsr.port:443] map[] [] []  []} {green IP kind-2-control-plane} {RUNNING}}: Connection to Network Registry Server is not available","app":"nse-discovery"}
  	267:time="2021-06-14T14:58:32Z" level=error msg="None of the tls certificates worked: <nil>"
  	269:time="2021-06-14T14:58:52Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	270:time="2021-06-14T14:58:52Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="26cd74961c307c59:63b82838c1f5c96a:26cd74961c307c59:1"
  	273:{"level":"info","ts":1623682732.475098,"caller":"nseinformer/nseInformerController.go:369","msg":"Error processing pod &{{ } {green7k6bh green nsm-system /apis/networkservicemesh.io/v1alpha1/namespaces/nsm-system/networkserviceendpoints/green7k6bh c8c7c650-9263-4013-bfab-a8b4d8edd0e1 3284 1 2021-06-14 14:56:52 +0000 UTC <nil> <nil> map[app:vl3-nse-green networkservicename:green nsepod.name:green-kind-2_vl3-nse-green-76bc7f4b96-pfsst wcm/nsr.addr:green.nispatil-wcm-cisco.com wcm/nsr.port:443] map[] [] []  []} {green IP kind-2-control-plane} {RUNNING}}: Connection to Network Registry Server is not available","app":"nse-discovery"}
  	321:time="2021-06-14T14:59:02Z" level=error msg="None of the tls certificates worked: <nil>"
  	323:time="2021-06-14T14:59:22Z" level=error msg="Error occurred while trying to establish connection to: green.nispatil-wcm-cisco.com:443. Error: context deadline exceeded"
  	324:time="2021-06-14T14:59:22Z" level=error msg="Failed to dial Network Service Registry at green.nispatil-wcm-cisco.com:443: context deadline exceeded" operation=initRegistryClient span="66dae72650f60a43:6f04655ba2ecefae:66dae72650f60a43:1"
  	327:{"level":"info","ts":1623682762.5984712,"caller":"nseinformer/nseInformerController.go:369","msg":"Error processing pod &{{ } {greenqvhtb green nsm-system /apis/networkservicemesh.io/v1alpha1/namespaces/nsm-system/networkserviceendpoints/greenqvhtb d0a5ebca-6c3f-4d65-b4cc-027bf680eba5 3283 1 2021-06-14 14:56:52 +0000 UTC <nil> <nil> map[app:vl3-nse-green networkservicename:green nsepod.name:green-kind-2_vl3-nse-green-76bc7f4b96-fx2bm wcm/nsr.addr:green.nispatil-wcm-cisco.com wcm/nsr.port:443] map[] [] []  []} {green IP kind-2-control-plane} {RUNNING}}: Connection to Network Registry Server is not available","app":"nse-discovery"}
  	375:time="2021-06-14T14:59:32Z" level=error msg="None of the tls certificates worked: <nil>"
  
  
  ./kind-2.kubeconfig/wcm-system/wcm-nse-operator-6fb5b6fb4c-8mfgn/logs.txt
  
  	13:{"level":"info","ts":1623682184.4402342,"logger":"cmd","msg":"Could not create ServiceMonitor object","error":"no ServiceMonitor registered with the API"}
  	14:{"level":"info","ts":1623682184.4405682,"logger":"cmd","msg":"Install prometheus-operator in your cluster to create ServiceMonitor objects","error":"no ServiceMonitor registered with the API"}
  	44:{"level":"error","ts":1623682550.3729696,"logger":"controller_connectivitydomainendpoint","msg":"An error occurred","component":"NSE","method":"UpdateObject","error":"Operation cannot be fulfilled on connectivitydomainendpoints.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject.func1\n\tcommon-operator-resources/resources.go:859\ncisco-app-networking.github.io/wcm-api/common-operator-resources.LogWCMComponent.UpdateObject\n\tcommon-operator-resources/resources.go:869\ncisco-app-networking.github.io/wcm-api/wcm-nse-operator/pkg/controller/connectivitydomainendpoint.(*ReconcileConnectivityDomainEndpoint).Reconcile\n\twcm-nse-operator/pkg/controller/connectivitydomainendpoint/connectivitydomainendpoint_controller.go:220\ncisco-app-networking.github.io/wcm-api/wcm-nse-operator/pkg/controller/connectivitydomainendpoint.(*LoggingConnectivityDomainEndpointReconciler).Reconcile\n\twcm-nse-operator/pkg/controller/connectivitydomainendpoint/connectivitydomainendpoint_controller.go:102\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	45:{"level":"error","ts":1623682550.3739138,"logger":"controller_connectivitydomainendpoint","msg":"An Error occurred","method":"Reconcile","operator":"connectivity domain endpoint","request namespace":"wcm-system","request name":"green","error":"Operation cannot be fulfilled on connectivitydomainendpoints.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\ncisco-app-networking.github.io/wcm-api/wcm-nse-operator/pkg/controller/connectivitydomainendpoint.(*LoggingConnectivityDomainEndpointReconciler).Reconcile.func1\n\twcm-nse-operator/pkg/controller/connectivitydomainendpoint/connectivitydomainendpoint_controller.go:91\ncisco-app-networking.github.io/wcm-api/wcm-nse-operator/pkg/controller/connectivitydomainendpoint.(*LoggingConnectivityDomainEndpointReconciler).Reconcile\n\twcm-nse-operator/pkg/controller/connectivitydomainendpoint/connectivitydomainendpoint_controller.go:102\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:235\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  	46:{"level":"error","ts":1623682550.3740582,"logger":"controller","msg":"Reconciler error","controller":"connectivitydomainendpoint-controller","name":"green","namespace":"wcm-system","error":"Operation cannot be fulfilled on connectivitydomainendpoints.wcm.cisco.com \"green\": the object has been modified; please apply your changes to the latest version and try again","stacktrace":"github.com/go-logr/zapr.(*zapLogger).Error\n\t/Users/nispatil/go/pkg/mod/github.com/go-logr/zapr@v0.1.1/zapr.go:128\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:237\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:209\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).worker\n\t/Users/nispatil/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.6.2/pkg/internal/controller/controller.go:188\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:155\nk8s.io/apimachinery/pkg/util/wait.BackoffUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:156\nk8s.io/apimachinery/pkg/util/wait.JitterUntil\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:133\nk8s.io/apimachinery/pkg/util/wait.Until\n\t/Users/nispatil/go/pkg/mod/k8s.io/apimachinery@v0.18.6/pkg/util/wait/wait.go:90"}
  
  
  ./kind-2.kubeconfig/kube-system/kube-scheduler-kind-2-control-plane/logs.txt
  
  	6:W0614 14:42:40.083387       1 authentication.go:296] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
  
  
  ./kind-2.kubeconfig/kube-system/kube-controller-manager-kind-2-control-plane/logs.txt
  
  	10:E0614 14:42:40.081973       1 leaderelection.go:331] error retrieving resource lock kube-system/kube-controller-manager: endpoints "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "endpoints" in API group "" in the namespace "kube-system"
  	222:E0614 14:50:08.285053       1 daemon_controller.go:290] nsm-system/wcm-nsmgr failed with : error storing status for daemon set &v1.DaemonSet{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"wcm-nsmgr", GenerateName:"", Namespace:"nsm-system", SelfLink:"/apis/apps/v1/namespaces/nsm-system/daemonsets/wcm-nsmgr", UID:"8172ed0a-007e-43e0-b03e-6ba5b76d9af6", ResourceVersion:"1956", Generation:1, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63759279007, loc:(*time.Location)(0x399e9e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"wcm-nsmgr", "membercore":"wcm"}, Annotations:map[string]string{"deprecated.daemonset.template.generation":"1"}, OwnerReferences:[]v1.OwnerReference{v1.OwnerReference{APIVersion:"wcm.cisco.com/v1alpha1", Kind:"MemberCore", Name:"wcm", UID:"74ff6219-bbb6-43c2-8e5c-ca30beb64736", Controller:(*bool)(0xc0019422ed), BlockOwnerDeletion:(*bool)(0xc0019422ee)}}, Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.DaemonSetSpec{Selector:(*v1.LabelSelector)(0xc001a14420), Template:v1.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:"", GenerateName:"", Namespace:"", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"app":"wcm-nsmgr", "membercore":"wcm"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kubelet-socket", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001a14440), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"nsm-socket", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001a14460), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"nsm-config-volume", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(0xc001ac0140), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}, v1.Volume{Name:"spire-agent-socket", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(0xc001a14480), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"wcm-nsmgr", Image:"nishantapatil3/nsmdp:vl3_latest", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort{v1.ContainerPort{Name:"", HostPort:5001, ContainerPort:5001, Protocol:"TCP", HostIP:""}}, EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"INSECURE", Value:"false", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"TRACER_ENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_HOST", Value:"wcm-jaeger.nsm-system", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_PORT", Value:"6831", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_K8S_ADDRESS", Value:"wcm-proxy-nsmgr:5005", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_ADDRESS", Value:"wcm-proxy-nsmgr:5006", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"nsm-socket", ReadOnly:false, MountPath:"/var/lib/networkservicemesh", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"kubelet-socket", ReadOnly:false, MountPath:"/var/lib/kubelet/device-plugins", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"spire-agent-socket", ReadOnly:true, MountPath:"/run/spire/sockets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"nsmd", Image:"nishantapatil3/nsmd:vl3_latest", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"INSECURE", Value:"false", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"TRACER_ENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_HOST", Value:"wcm-jaeger.nsm-system", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_PORT", Value:"6831", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_K8S_ADDRESS", Value:"wcm-proxy-nsmgr:5005", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_ADDRESS", Value:"wcm-proxy-nsmgr:5006", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PREFERRED_REMOTE_MECHANISM", Value:"IPSEC", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"nsm-socket", ReadOnly:false, MountPath:"/var/lib/networkservicemesh", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"nsm-config-volume", ReadOnly:false, MountPath:"/var/lib/networkservicemesh/config", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}, v1.VolumeMount{Name:"spire-agent-socket", ReadOnly:true, MountPath:"/run/spire/sockets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(0xc001267530), ReadinessProbe:(*v1.Probe)(0xc001267560), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"nsmd-k8s", Image:"nishantapatil3/nsmd-k8s:vl3_latest", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"INSECURE", Value:"false", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"POD_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001a144a0)}, v1.EnvVar{Name:"POD_UID", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001a144e0)}, v1.EnvVar{Name:"NODE_NAME", Value:"", ValueFrom:(*v1.EnvVarSource)(0xc001a14520)}, v1.EnvVar{Name:"TRACER_ENABLED", Value:"true", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_HOST", Value:"wcm-jaeger.nsm-system", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"JAEGER_AGENT_PORT", Value:"6831", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_K8S_ADDRESS", Value:"wcm-proxy-nsmgr:5005", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PROXY_NSMD_ADDRESS", Value:"wcm-proxy-nsmgr:5006", ValueFrom:(*v1.EnvVarSource)(nil)}, v1.EnvVar{Name:"PREFERRED_REMOTE_MECHANISM", Value:"IPSEC", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"spire-agent-socket", ReadOnly:true, MountPath:"/run/spire/sockets", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0019424f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"wcm-nsmgr-service-account", DeprecatedServiceAccount:"wcm-nsmgr-service-account", AutomountServiceAccountToken:(*bool)(nil), NodeName:"", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000d54600), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(nil), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}}, UpdateStrategy:v1.DaemonSetUpdateStrategy{Type:"RollingUpdate", RollingUpdate:(*v1.RollingUpdateDaemonSet)(0xc00121c0c0)}, MinReadySeconds:0, RevisionHistoryLimit:(*int32)(0xc00194250c)}, Status:v1.DaemonSetStatus{CurrentNumberScheduled:0, NumberMisscheduled:0, DesiredNumberScheduled:0, NumberReady:0, ObservedGeneration:0, UpdatedNumberScheduled:0, NumberAvailable:0, NumberUnavailable:0, CollisionCount:(*int32)(nil), Conditions:[]v1.DaemonSetCondition(nil)}}: Operation cannot be fulfilled on daemonsets.apps "wcm-nsmgr": the object has been modified; please apply your changes to the latest version and try again
  
  
  ./kind-2.kubeconfig/kube-system/kindnet-xwjsq/logs.txt
  
  	4:I0614 14:43:34.625847       1 main.go:104] Failed to get nodes, retrying after error: Get https://10.96.0.1:443/api/v1/nodes: dial tcp 10.96.0.1:443: i/o timeout
  
  

